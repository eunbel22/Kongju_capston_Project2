from fastapi import FastAPI, Header, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import json

from search_utils import build_faiss_index, search_similar_paragraph
from llm_utils import generate_answer_ollama

# ğŸ” API í‚¤ ì„¤ì •
API_KEY = "porty-secret-2025"  # ì„œë²„ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬í•  í‚¤

# FastAPI ì•± ì„ ì–¸
app = FastAPI()

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ë˜ëŠ” ì™¸ë¶€ ì ‘ê·¼ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í•„ìš”í•œ ê²½ìš° ì œí•œ ê°€ëŠ¥
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ë°”ë”” ì •ì˜
class Query(BaseModel):
    question: str

# ë¬¸ì¥ ë°ì´í„° ë¡œë“œ
with open("split_results.json", "r", encoding="utf-8") as f:
    data = json.load(f)["results"]
paragraphs = [entry["content"] for entry in data]

# FAISS ì¸ë±ìŠ¤ ì¤€ë¹„
print("[1] ë¬¸ì¥ ë¡œë“œ ì™„ë£Œ:", len(paragraphs), "ê°œ")
index, vectorizer = build_faiss_index(paragraphs)
print("[2] FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

# ì§ˆë¬¸ ì²˜ë¦¬ API
@app.post("/ask")
async def ask(query: Query, x_api_key: str = Header(...)):
    # ğŸ” API í‚¤ ì¸ì¦
    if x_api_key != API_KEY:
        raise HTTPException(status_code=403, detail="âŒ Invalid API Key")

    user_input = query.question

    # ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
    matched = search_similar_paragraph(user_input, index, vectorizer, paragraphs)
    combined_context = "\n".join(matched[:5])  # ìµœëŒ€ 5ë¬¸ì¥ ì œí•œ

    # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¹ì‹ ì€ ê³µì£¼ëŒ€í•™êµì— ê´€í•œ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.

- ì ˆëŒ€ë¡œ ë‹¤ë¥¸ ëŒ€í•™êµ(ì˜ˆ: êµ­ë¯¼ëŒ€í•™êµ, ì„œìš¸ëŒ€ ë“±)ë¥¼ ì–¸ê¸‰í•˜ê±°ë‚˜ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.  
- ê³µì£¼ëŒ€í•™êµëŠ” ìº í¼ìŠ¤ë³„ë¡œ ìœ„ì¹˜ê°€ ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì‹¤ì œ í–‰ì •êµ¬ì—­ì„ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.  
- íŠ¹íˆ "ê³µì£¼ì‹œ ì²œì•ˆë™", "ê³µì£¼ê´‘ì—­ì‹œ ì²œì•ˆë™" ê°™ì€ ì˜ëª»ëœ ì§€ëª…ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. 
- ì²œì•ˆìº í¼ìŠ¤ëŠ” ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ, ì˜ˆì‚°ìº í¼ìŠ¤ëŠ” ì¶©ì²œë‚¨ë„ ì˜ˆì‚°êµ°, ë³¸êµëŠ” ì¶©ì²­ë‚¨ë„ ê³µì£¼ì‹œì— ìœ„ì¹˜í•©ë‹ˆë‹¤.


ì•„ë˜ì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ ë¬¸ë‹¨ì„ ì°¸ê³ í•˜ì—¬ ê³µì£¼ëŒ€í•™êµ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

[ì§ˆë¬¸]
{user_input}

[ê´€ë ¨ ë¬¸ë‹¨]
{combined_context}

[ë‹µë³€]
"""

    # LLM í˜¸ì¶œ (Ollama)
    try:
        answer = generate_answer_ollama(prompt)
    except Exception as e:
        answer = f"âš ï¸ LLM ì‘ë‹µ ì˜¤ë¥˜: {e}"

    return {
        "question": user_input,
        "matched_paragraphs": matched,
        "answer": answer
    }
